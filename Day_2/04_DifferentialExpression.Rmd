---
title: "Spring Into Bioinformatics"
subtitle: "Differential expression"
author: "Melanie Smith"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE,
    fig.align = "center",
    fig.cap = "yes",
    results = "hide"
)
if (interactive()) setwd(here::here("Day_2"))
```

* TOC
{:toc}

## Session Themes and Outcomes

In this session we're going to learn a few things about performing a differential expression analysis on gene expression data in `R`.

At the end of this session, you should be able to do the following tasks:

1. Read a counts table into `R` including:
  + set the required delimiter
  + selectively remove unwanted columns
  + tidy up the column names
2. Explore basic data paramaters such as library size
3. Create a `DGEList` object
4. Assess sample similarity and identify outliers using Unsupervised Clustering
5. Perform a simple differential expression analysis

Now that we have our data in a nicely formatted file, we can move to `R` and follow a fairly standard workflow.
Along the way, we'll come across a few useful packages, data structures and coding tricks which will be applicable in many other contexts.

The packages we'll use for this include not only the `tidyverse`, but a few other packages which are hosted on [Bioconductor](www.bioconductor.org), such as `limma`, `edgeR` and `AnnotationHub`.
We'll also add the `magrittr`,`pander` and `scales` packages as they contain some useful additional utilities.

```{r loadPackages}
library(limma)
library(Glimma)
library(edgeR)
library(AnnotationHub)
library(tidyverse)
library(magrittr)
library(scales)
library(pander)
library(ggrepel)
library(RColorBrewer)
```

## Data Setup

### Import

First we should import the file we created using `featureCounts`.
Please take a moment to check the location of the `counts.out` file you created in the last session to ensure the assignment of the location to the _file_ object is correct.

```{r counts}
file <- "../data/2_alignedData/featureCounts/counts.out"
rawCounts <- read_delim(file, comment = "#", delim = "\t")
```

This file has the gene identifiers in the first column, followed by the chromosome number, start, end, strand and length information (recall that we have subset our data to only include mouse chromosome 1), with the remaining columns containing the name of the `bam` file and the number of reads aligning to each gene.
The first thing we might like to do is to remove the columns which don't contain the count data we require today, and tidy up those column names.

```{r setColnames}
countData <- dplyr::select(rawCounts, -c(Chr, Start, End, Strand, Length)) %>%
  set_colnames(basename(colnames(.))) %>%
  set_colnames(str_remove(colnames(.), ".trimmedAligned.sortedByCoord.out.bam"))
```

This code chunk is doing quite a bit of work for us. Firstly we have taken our original `rawCounts` object with the ugly column names and used the `select()` function from the `dplyr` package to remove the five columns we don't need for our analysis. Next we're removing the file address from the column names by calling the `basename()` function on the `colnames()` function, inside of the `set_colnames()` function. We have used the **.** (full stop) in the `colnames()` function call to tell `R` to use the object we piped in using the `%>%`. Lastly we use the same _nesting_ of functions idea to remove the long file name and extension from the column names using the `str_remove()` function from the `stringr` package we used on Day 1.
That looks much cleaner and we haven't lost any important information but we're not quite done.
The group information we need for the differential expression is locked in the samplename.
Next we can split the sample ID from the group information and save that information in a dataframe for later use.

```{r splitSampleID}
sampleGroups <- as.data.frame(names(countData[-1]), stringsAsFactors = FALSE) %>%
  set_colnames(., "samplename") %>%
  tidyr::separate(., col = samplename, into = c("samplename", "group"), remove = TRUE)
```

Now we have a small table of metadata regarding our samples.
We can also tidy up our countData table column names a little more by moving the gene IDs to row names and removing the group information after the sample name.

```{r sampleName}
countData <- as.data.frame(countData) %>%
  column_to_rownames("Geneid")
colnames(countData) <- sampleGroups$samplename
```

### Create a DGE List

The main object type we like to use for differential gene expression is a `DGEList`, which stands for Digital Gene Expression List, and is an object used by _edgeR_ to store count data.
This object is more complex than others we have looked at in `R` so far because it contains a number of _slots_ for storing not only our data, but also different paramaters _about_ the data.
The `DGEList` objects have two mandatory elements, with the first being our counts data, and the second being our sample information.
Recall that above we have made the gene IDs the row names and the sample IDs the column names.

Here's one way to create a `DGEList`.

```{r dgeList}
dgeList <- countData %>%
    DGEList() %>%
    calcNormFactors()
```

Here we have taken our counts table with gene IDs as row names and sample IDs as column names and put it in to a `DGEList` object, called `dgeList`, and called the `calcNormFactors()` function to calculated the normalisation factors, which can be seen in `dgeList$samples`.

If we decided to fit our counts using a negative binomial model (for discrete data), these `norm.factors` would be included in the model to adjust for variations in the library size and count distributions (for an interesting post on what "fitting" a model is see [fit] (https://diamondage.com/2017/06/03/what-does-it-mean-to-fit-a-model-anyway/).

We have chosen to use a different approach for our analysis today, but taking the time to include the _calculation of normalisation factors_ step as we form the `DGEList` object is still good practice as it allows us to change methodology part way through our planned analysis if we determine the negative binomial model is better suited to our data.

Take a moment now to run this next code chunk and inspect the `samples` data frame sitting inside the `DGEList` object we have just created.

```{r samples}
dgeList$samples
```

`R` understood that the column names from our counts table contained the sample IDs for our project and created the `samples` data frame inside the `DGEList` object. `lib.size` and `norm.factors` have also been calculated from the counts table and incorporated into the element.
We haven't yet included any information describing our samples. In the `samples` element, we can set the group variable we previously took from the sample IDs by running:

```{r setGroups}
dgeList$samples$group <- sampleGroups$group %>%
    factor(levels = c("cbc", "skm"))
```

Take another moment now to inspect the `samples` data frame again and you will now see what was previously a row of 1s is now populated with the appropriate tissue type.

```{r samplesGroups}
dgeList$samples
```

As a small note of warning, keep in mind that we did not at any time alter the order in which our samples were being reported. This allowed us to simply _cut_ the information from one table and _paste_ it into another. There are ways of using _mutating joins_ to ensure order is never corrupted including `left_join`, `right_join`, `inner_join` and others.

It is always worth taking the time to perform a "sanity check" to ensure the sample names and groups are correctly aligned before you continue.

### Add Gene Information

A common, but optional element that we can include in a `DGEList`, is one called `genes`.
This is where we can place information such as the genomic location, the gene symbol and anything else we think is going to be relevant.
First, we need to find this information though, and we'll use the package `AnnotationHub` which contains the *metadata* for all of the annotation packages included in Bioconductor.

```{r ah}
ah <- AnnotationHub()
```

The structure of this new object `ah` is quite advanced. Take a moment to type in the object name and run the line, you'll get an informative summary of all available annotation packages.

```{r viewAh}
ah
```

Note that we have numerous data providers, species and data classes.
The column on the left (AH####) is a shorthand ID we can use to retrieve any of these annotation objects.

We can also subset the Annotation Hub object to help us find what we're looking for.
In the following code, we're restricting our search to mouse, and specifying Ensembl as our data source.

The final line looks for an object of class `EnsDb` which is a database object containing a large amount of information, but in a relatively user-friendly way.

```{r subset_ah}
ah <- ah %>%
  subset(species == "Mus musculus") %>%
  subset(dataprovider == "Ensembl") %>%
  subset(rdataclass == "EnsDb")
```

We have now subset `ah` and removed most of the information we don't need (ie infromation related to other species and other data providors). 
When we inspected `ah` above we saw that the latest release was **AH69210 | Ensembl 96 EnsDb for Mus Musculus**.
Today we will use this annotation record and define it as the object `ensDb`

```{r ensDb}
ensDb <- ah[["AH69210"]]
ensDb
```

There are many helper functions for extracting data from this package, such as `transcripts()`, `promoters()` and `genes()`.
We want gene information today, so let's just use that function. 
Note that after we obtain the data, we're using `subset()` to ensure we only keep the data from chromosome 1.

```{r genes}
genesGR <- genes(ensDb) %>%
    subset(seqnames == 1)
```

This object is a `GenomicRanges` (or `GRanges`) object and these are the bread & butter of genomic analysis in R. 
We could spend hours just looking at these, but the main point is that on the right of the gene IDs we have the chromosome (`seqnames`) followed by the range of bases the genes is contained within and the strand the gene is located on (note that _start_ and _end_ positions are both **1-based** relative to the 5' end of the plus strand of the choromosome, even when the range is on the minus strand).
This is the core `GRanges` element. Run the following code chunk to return this information using the function `granges()`

```{r granges}
granges(genesGR)
```

Underlying each `GRanges` object is a `seqinfo` object and these contain all of the genomic information about chromosome names and lengths.
If comparing two `GRanges` objects, they must have identical `seqinfo` objects otherwise the comparison will return an error.
This actually makes perfect sense, but can create issues when comparing data from UCSC, NCBI and Ensembl as they all use different formats for their chromosome names, even though they're based on the same assemblies.

```{r seqinfo}
seqinfo(genesGR)
```

To the right of the pipes, we have the metadata columns, accessed using the function `mcols()`.
Notice this returns a `DataFrame` which is a slightly more controlled version of a `data.frame`.
The differences are beyond the scope of this course, but they can easily be coerced to a `data.frame` using `as.data.frame`.
If you want to use the `dplyr` functions on them, you will need to go through this step.

```{r mcols}
mcols(genesGR)
```

Before we place this information into the `genes` element of our `DGEList` object we will remove columns that are redundant for our purposes today, and keep only the four most useful ones. We can achieve this by calling the `mcols()` function on our `GRanges` object. Firstly we use the square brackets to subset the `genesGR` object we created earlier, and then by using the assignment operator (<-) to overwrite this subsetted element back into the object.

```{r newMcols}
mcols(genesGR) <- mcols(genesGR)[c("gene_id", "gene_name", "gene_biotype", "entrezid")]
```

If we wish to add this to our `DGEList`, note that the order of genes will be completely different.
To fix this, we will use the `rownames` of our `DGEList` object to reorder the `genes` object.
Taking the time to ensure that the two gene lists are in the same order is important because `R` will give no warning or error to inform us if the two gene lists are in different orders. `R` will not check that these two objects are compatible.

```{r addGenes}
dgeList$genes <- genesGR[genesGR$gene_id %in% rownames(dgeList),]
```

Here we have used square brackets `[]` to subset and reorder the `genesGR` object such that it now only contains the genes in our `dgeList` object, and in the same order.

Now when we subset our `DGEList` by gene, the `genes` element will also be subset accordingly and the initial relationships will be maintained. Take a moment to inspect the first four elements of our `dgeList` object by running the code chunk below.

```{r dge1to4}
dgeList[1:4,]
```

You will notice that the `degList$genes` element is now populated with the information from `annotationHub` we downloaded earlier, and that `dgeList$counts` and `degList$genes` are in the same order.

## Data QC

### Undetectable genes

You may have noticed that no reads aligned to a number of the genes contained in this dataset. As common practice we remove genes with zero counts across all samples before we continue with our initial data exploration.
Rather than inspect our data one line at a time looking for zeros we can use `R` to perform a logical test to see how many genes were not detected in our dataset.
First we'll add up the total counts for every gene and see how many received at least one count. In the following code chunk we will take the `counts` element from our `DGEList` object and pipe it into the function `rowSums()` which will output a named number vector with a single value (the sum of each gene) for each gene. This vector is in turn piped into another function `is_greater_than()` which will ask the logical question _"is the value greater than the given value"_, with the given value being **0**. We then pipe the **TRUE**/**FALSE** answers to this logical question into `table` which will provide us with a simple two number summary.

```{r checkZeroes}
dgeList$counts %>% 
    rowSums() %>%
    is_greater_than(0) %>%
    table
```

Any genes that fail our test (ie the sum of which are not greater than zero) will be counted in the **FALSE** column, and any genes that pass our test (ie the sum of which is greater than zero) will be counted in the **TRUE** column.
We can see that a proportion of genes were not expressed or were _undetectable_ in our original samples.
A common approach would be to remove undetectable genes using some metric, such as **Counts per Million reads**, also known as `CPM`.
We could consider a gene detectable if returning more than 1CPM, in every sample, from one (usually the smaller), of the treatment groups.

Although our dataset is small (6/8 libraries are < 1e6 reads), we usually deal with libraries between 20-30million reads. In the context of the more usual library size a CPM of 1 equates to 20-30 reads aligning to a gene, which we test in every sample from a treatment group.
Here our smallest group is 4 so let's see what would happen if we applied the filter of > 1 CPM in 4 samples.

First we'll calculate the `CPM` for each gene in each sample, and then we'll apply a logical test to each value checking whether it's greater than 1.
Next, we'll add these up for each gene (i.e. row) and this will give us the total number of samples for each gene, that passed our criteria of **CPM > 1**.
Finally, we'll check for genes which passed our criteria in more than 4 samples, as our smallest group is 4. 
We could also have used the function `is_weakly_greater_than()` which would test for equality ($\geq$) instead of strictly greater than ($>$).

```{r checkFiltering}
dgeList %>%
    cpm() %>%
    is_greater_than(1) %>%
    rowSums() %>%
    is_greater_than(4) %>%
    table()
```

Losing about 1/3 of the genes is pretty common, so let's now apply that to our dataset.
The object `genes2keep` below will be a `logical` vector deciding on whether we keep the gene for downstream analysis, based purely on whether we consider the gene to be detectable.
We'll create a new `DGEList` object by subsetting our primary one using the `[]` trick we learned earlier.
We are creating a new object here so that if we change our mind about our filtering strategy, we don't have to rerun all the code above.

```{r dgeFilt}
genes2keep <- dgeList %>%
    cpm() %>%
    is_greater_than(1) %>%
    rowSums() %>%
    is_greater_than(4)

dgeList_Filtered <- dgeList[genes2keep,] %>%
  calcNormFactors()
```

#### A note on normalisation

There are many different metrics used for count data normalisation including **T** ranscripts **P** er **M** illion mapped reads (TPM), **C** ounts **P** er **M** illion mapped reads (CPM) and  **R** eads **P** er **K** ilobase per **M** illion mapped reads (RPKM). We have already use **CPM** in our anlaysis. The _Counts Per Million_ metric takes our raw counts and performs a simple normalisation to account for differences in library size between samples. Put simply, the `cpm()` function we use takes the raw/estimated counts and divides each count by the sample library size before multiplying each count by 10^6^ with the equation:
$CPM_i = 10^6.(\frac{X_i}{N})$
Where $X_i$ is the gene in consideration and $N$ is the sample library size. Often in RNA-seq we use **TPM** which is based on a standard gene size compared to **RPKM** which takes gene length into account. Normalisation is a bigger topic than you might think at first and is (mostly) outside of the scope of our session today. For an accessible introduction to RNA-seq normalisation you can read this [blog post](http://robpatro.com/blog/?p=235) from Rob Patro, or [this one](https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/) written by Harold Pimentel.

In our session today we will be using `edgeR`s normalisation strategy. `edgeR` does not use RPKM, TPM _etc_. to normalise but rather has its own `calcNormFactors()` function.

This is because `edgeR` needs to normalise for:

- Sequencing depth (thats what RPKM etc. deal with)
- Library composition (ie different samples contain different active genes)

The process edgeR uses for normalisation (simplified) is as follows:

Step 1: Remove all undetectable genes (remove genes with zero read counts in all samples)

Step 2: Pick one sample to be the "reference sample".

- this is the sample that `edgeR` will use to normalise all other samples against
- what makes a good _reference sample_? `edgeR` avoids using _extreme_ samples and instead attempts to identify the most **average** sample
- to pick a reference sample edgeR will:
    + a. Scale each sample by its total read counts.
    + b. For each sample, determine the value such that 75\% of the scaled data are equal to or smaller than it
    + c. Average the 75^th^ quantiles
    + d. The "reference" samples is the one who's 75^th^ quantile most closely matches the average

Step 3: Select the genes for calculating the scaling factors. This is done separately for each sample relative to the _reference sample_

- the genes used for calculating the scaling factors may be different for each sample
- edgeR filters out _biased genes_ by looking at, and then excluding genes with large log fold differences

Step 4: Calculate the weighted average of the remaining log~2~ ratios 

Step 5: Convert the weighted average of log~2~ values to _"normal numbers"_

Step 6: Centre the scaling factors around $1$

- the _centering_ is done by dividing each raw scaling factor by their geometric mean

More information about `edgeR` normalisation can be found [here](https://youtu.be/Wdt6jdi-NQo) and [here](https://academic.oup.com/bioinformatics/article/26/1/139/182458).


Let's compare the distributions of the two datasets (cbc and skm), using CPM on the log2 scale.
In the following, the command `par(mfrow = c(1,2))` is a base graphics approach and sets the plotting `par`ameters to be a `m`ulti=`f`eature layout, with 1 row and 2 columns.
We set these paramaters because the convenient function `plotDensities()` we are calling below uses base graphics, not `ggplot2`.

```{r plotCPM, fig.cap="Comparison of logCPM distributions before (A) and after (B) filtering for undetectable genes. Values on the x-axis represent logCPM"}

col <- brewer.pal(nrow(dgeList$samples), "Paired")
par(mfrow = c(1,2))
dgeList %>%
    cpm(log = TRUE) %>%
    plotDensities(legend = FALSE,
                  main = "A. Before Filtering",
                  col=col)
dgeList_Filtered %>%
    cpm(log = TRUE) %>%
    plotDensities(legend = FALSE,
                  main = "B. After Filtering",
                  col=col)
par(mfrow = c(1,1))
```

Note the peak at the left in the first plot around zero.
This is all of the genes with near-zero counts.
Then note that this peak is missing the second plot, confirming that we have removed most of the undetectable genes.
Ideally we would like to see that the peak around zero has been removed after filtering, and that the samples all have approximately the same distribution of counts. Keeping in mind that we have significantly subset our original `fastq` data during alignment earlier such that we only have genes from mouse chromosome 1.

### Library Sizes

Next we should check our library sizes.
It does appear that the two tissue types have a different profile of reads. There could be a number of reasons for seeing differences between groups including sequencing batch effects, differences in the RNA quality from different tissues or extractions, or lab operations being performed by different staff.
This is not ideal but most modelling approaches will be able to handle this.

```{r plotLibSizes, fig.cap = "Library Sizes after filtering for undetectable genes."}
dgeList_Filtered$samples %>%
    ggplot(aes(group, lib.size, fill = group)) +
    geom_boxplot() +
    scale_y_continuous(labels = comma) +
    labs(x = "Tissue Type", y = "Library Size") +
    theme_bw() 
```

We've used he function `comma` from the `scales` package here to help us interpret the y-axis.
For most vertebrate datasets we expect libraries of >20million reads, but as we've given you a significantly reduced dataset, these numbers are pretty acceptable.

### Unsupervised clustering of samples

One of the first steps in exploring our gene expression data is that of unsupervised clustering in the form of a multi-dimensional scaling plot (MDS), Principal Component Analysis (PCA) or similar. By _unsupervised_ here we mean to say that we haven't _told_ `R` how many groups we are expecting to see, or given any information about which samples we expect to see clustering closely together. Visually inspecting the data in this way allows us to start to understand the extent to which any differential expression can be detected before we have performed any statistical tests. It may also help us to identify any outliers in our samples, or perhaps a factor we haven't yet considered that should be included when fitting our model later.

#### Multi-dimensional Scaling Plot (MDS)

An important first exploration of our sequencing data is the MDS plot.

The `plotMDS()` function from the `limma` package creates a temporary log fold change between pairs and plots samples on a two-dimensional scatterplot so that distances on the plot approximate the typical $log_2$ fold changes between the samples.

```
A simplified example of how we calculate the logFC for our MDS plot.
```
1. For a given counts table eg.

|     |sample_1|sample_2|sample_3|
|------|-----:|-----:|-----:|
Gene_1|3.0|0.25|2.8|
Gene_2|2.9|0.8|1.0|
Gene_3|2.2|1.0|1.5|
....

2. We take our gene counts and calculate the logFC between each pair of genes
  + logFC Gene_1: sample_1 versus sample_2 $= log(\frac{3}{.25}) = 3.58$

  + logFC Gene_2: sample_1 versus sample_2 $= log(\frac{2.9}{.8}) = 1.86$

  + _Continue calculating the logFC between each pair of genes_
  
3. Lastly, take the average of the absolute value of the logFC among genes

**nb**: we take the absolute value so the negative log fold changes don't cancel out the positive ones
  
4. We can now use these _distances_ between samples to plot our MDS.

Thankfully we don't need to perform all of these calculations by hand, or even write our own script to do so

```{r mds, fig.cap = "MDS showing two clear groups in the data. limma::plotMDS"}
plotMDS(cpm(dgeList_Filtered, log = TRUE))
title(main = "Multi Dimensional Scaling Plot \nMouse Chromosome 1")
```

Here we see that the Leading logFC on dimension 1 appears to seperate the samples by tissue type suggesting that as we set out to investigate - there is a difference in gene expression between cerebellar cortex (cbc) and skeletal muscle (skm). 

<span style="color:red">WARNING: it is easy to observe the difference between our groups on the MDS plot and assign them directly to tissue type. The files we are using here are part of a much larger research effort and as such there is much information not being assessed. eg. were our samples all sequenced at the same time, on the same machine? The differences we observe could be due to something we call _batch effects_.</span>

Batch effects can be defined as _systematic non-biological variation between groups of samples (or batches) due to experimental artifacts_. Batch effects are a complication of high-throughput studies which occur when measurements are affected by laboratory conditions. The topic of **batch effects** and how to account for them deserves its own session but we don't have the time to delve into that here. If you are interested in reading more about batch effects and how to overcome them the [rna-seqblog](https://www.rna-seqblog.com/tag/batch-effects/) has a number of interesting articles discussing the topic.  

We can use the `plotMDS()` function directly to create an MDS plot as we did above, or assign the data created to an object that we can pipe into ggplot for a presentation ready figure.

```{r mdsObject, fig.show = 'hold'}
mds <- dgeList_Filtered %>%
  cpm(log = TRUE) %>%
  plotMDS()
```

The following chunk wraps the plotting of our MDS plot inside `plotly::ggplotly()` which takes a `ggplot` object and makes it interactive.
You may notice that `label` was included as a plotting aesthetic, but no labels were added as a layer in ggplot2.
These will instead be added once the plot is made interactive (try hovering the mouse over one of the points on the plot to see what we mean by _interactive_).
Interactive plots will only be interactive in the **Viewer** tab or when compiling an RMarkdown document to an html format, and will remain static if rendering to an MS Word document or pdf.

```{r plotMDS, fig.cap = "MDS showing two clear groups in the data", results='asis'}
plotly::ggplotly(
  as.data.frame(cbind(dim1=mds$x,dim2= mds$y)) %>%
        rownames_to_column("sample") %>%
        as_tibble() %>%
        left_join(rownames_to_column(dgeList_Filtered$samples, "sample")) %>%
        ggplot(aes(x = dim1, y = dim2,
                   colour = group,
                   label = sample)) +
    xlab("Leading logFC Dim 1") +
    ylab("Leading logFC Dim 2") +
        geom_point(size = 3) +
        theme_bw()
)
```

In the spirit of interactive plots available in `R`, run the following code chunk to create an interactive MDS plot as an HTML page using `Glimma::glMDSPlot`. If you set $launch=TRUE$ this code chunk will open a new browser window containing an MDS plot in the left panel and a bar plot showing the proportion of variation explained by each dimension in the right panel. 

```{r plotMDS_Glimma}
dgeList_Filtered %>%
  cpm(log=TRUE) %>%
  glMDSPlot(., labels=rownames(dgeList_Filtered$samples),
            groups=dgeList_Filtered$samples$group,
            launch=TRUE)
```

#### Tasks

1. *Try clicking on the bars of the bar plot to change the pair of dimensions being plotted on the MDS.*
2. *What might account for the variation between dimension 2 and dimension 3?*

#### PCA

Next we might choose to perform a Principal Component Analysis on our data, commonly abbreviated to PCA.
This time, let's take our CPM values & asses them on the log2 scale to make sure our PCA results are not heavily skewed by highly expressed genes.
Our first step is to create a new object to hold the PCA results. In the following code chunk we take our filtered DGEList obeject `dgeList_Filtered` and pipe it to the `cpm()` function we used earlier to calculate the CPM values for each gene prior to setting the filtering threshold. We have made one small change here by including $log = TRUE$ in the function call. By default this is $log_2$. Next we pipe the $log_2$CPM values into the `t()` function. This will _transpose_ the matrix of counts such that the matrix now has genes in the columns and samples in the rows, which we then pipe into `prcomp` from the `stats` package. `prcomp()` returns a list with class "prcomp" containing a number of useful components.

To find out more about `prcomp` try typing `help("prcomp")` into the console. This will open the R Documentation for this function in the `Help` tab.

```{r pca}
pca <- dgeList_Filtered %>%
    cpm(log = TRUE) %>%
    t() %>%
    prcomp() 
```

In our DGEList, we have the genes as the variables of interest for our main analysis, however for the PCA we're looking at out samples as the variables of interest.
The third line in the above code chunk has transposed (`t()`) the matrix returned by `cpm(log = TRUE)` to place the samples as the rows, which is where the function `prcomp()` expects to see the variables of interest.

Run the next code chunk for a quick inspection of the results shows that the first two components capture most of the variability, as expected.
Beyond this observation, the details of PCA are beyond what we can cover here.

```{r summaryPca, results='asis'}
summary(pca)$importance %>%
  pander(split.tables = Inf)
```

Just as we did with the MDS plot, we can plot our PCA results to see if samples group clearly with their tissue type based on our main two principal components (ie PC1 and PC2).
Much the same as the MDS plot, any clear separation of our groups of interest can be considered a positive sign that we will find differentially expressed genes.

```{r plotPCA, fig.cap = "PCA showing two clear groups in the data", results='asis'}
plotly::ggplotly(
    pca$x %>%
        as.data.frame() %>%
        rownames_to_column("sample") %>%
        as_tibble() %>%
        dplyr::select(sample, PC1, PC2) %>%
        left_join(rownames_to_column(dgeList_Filtered$samples, "sample")) %>%
        ggplot(aes(x = PC1, y = PC2,
                   colour = group,
                   label = sample)) +
        geom_point(size = 3) +
        theme_bw()
)
```

Multi-Dimensional Scaling can look similar to PCA, but asks a slightly different question of the data. PCA creates plots based on _correlations between samples_, MDS creates plots based on _distances between samples_ (here logFC between genes). Both methods return the results:
1. Coordinates for a graph
2. Percent of variation each axis accounts for
3. Loading scores (to determine which variables have the largest effect)

It is common to perform one or both of these analyses before starting a differential expression analysis but rest assured that _usually_ results found under both methods will reveal similar patterns in your data.

For a great tutorial on multi-dimensional scaling check out _"StatQuest: MDS and PCoA"_ [here](https://youtu.be/GEn-_dAyYME), and a companion vidoe about PCA titled _"StatQuest: Principal Component Analysis (PCA), Step-by-Step"_ [here](https://youtu.be/FgakZw6K1QQ).

#### Tasks

1. *How much variation is accounted for in PC1 and PC2 combined?*
2. *Using the code chunk above as a template, plot PC3 and PC4 using* `ggplot` *and wrapping with* `plotly::ggplotly` *to investigate other sources of variation.*

## Differential Expression

In the previous sections we have worked with read counts, which are a discrete value and formally cannot be modelled using the assumption of normally distributed data (recall that counts data typically approximate a **negative binomial** distribution, not a **normal** distribution).

The failure to meet the assumption of normality rules out linear models and t-tests for RNA-Seq, so many packages have been developed which use the negative binomial distribution to model these counts (e.g. `edgeR` and `DESeq2`).

An alternative was proposed by [Law et al.](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29), where they apply a system of weights to the counts which allow the assumption of normality to be applied.
This method is called `voom` and we'll use this today.

### Voom transformation and calculation of variance weights

First, lets set up a model matrix to specify the model to be fitted.

```{r modelMatrix}
model_matrix <- model.matrix(~ + group, data = dgeList_Filtered$samples)
```

The above specifies a model where each coefficient corresponds to a group mean. Importantly we have used the `samples` elemenet of the `DGEList` object to set the model matrix. By using the `DGEList` object we ensure that the samples (and therefore the group assignment) has been given in the same order as the counts table.

#### Tasks

1. Take a moment to inspect the `model_matrix` object. You can do this by simply typing the object name into the console and hitting the <kbd>Enter</kbd> key.
2. What information has been added here?
3. What could happen if the group assignment wasn't given in the same order as the counts table?

Next we will 
```{r voom}
voomData <- voom(dgeList_Filtered, model_matrix, plot = TRUE)
```

Note that running the `voom()` function without the `model_matrix` object will add a design matrix to the data based on the `group` column of the `DGEList` object but which we chose to specify explicitly. This is something of a style choice, but either way we can now use the **voom object** to perform a simple linear regression on each gene, which amounts to a t-test in this dataset.

From here it's a simple matter to code the analysis and inspect results.

A lot of analysis is performed in the following code chunk:

1. We'll use `lmFit()` to fit the model for every gene using the design matrix in `voomData`. Note that we're not using CPM, but are instead fitting the counts directly, after incorporation of the [voom-derived weights](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-2-r29).
2. Next we moderate the variances using an empirical Bayes approach. This uses the assumption that our variance estimates will be a mix of overestimates and underestimates, and shrinks them all towards a central value. As a strategy, this is widely accepted and has been shown to increase power and reduce false positives.
3. Finally, we'll create a list of all genes with a summary of the results which we then convert to a `tibble`. The last step will remove the gene IDs (i.e. the row names), but because we've included our gene information in the `DGEList` object, this will be added to the results and we'll still know which gene is which (now we see why we needed to ensure the `genesGR` object was added in the same order as the `countData` object).

```{r topTable}
topTable <- voomData %>% 
    lmFit() %>%
    eBayes %>%
    topTable(coef = "groupskm", n = Inf) %>%
    as_tibble()
```

When we call the coefficient `groupskm` in the `topTable` function we are using the column name to specify which coefficient or contrast of the linear model is of interest

Note that the GRanges information has been coerced into columns to form a `data.frame`/`tibble` and that looks a bit messy.
To tidy things up, the following code will join all of the genomic co-ordinates into a single column, rename a few columns on the fly and by not asking for `ID.width` & `ID.gene_biotype`, we've saved ourselves dealing with a few redundant columns.
We could actually add this to the chunk above to save forming then modifying an `R` object, but it's been left separate for clarity.

### Tasks

1. Take a quick look at the `topTable` object before and after the tidy up by typing `topTable %>% head()` into the console and hitting the <kbd>Enter</kbd> key.

```{r editTopTab}
topTable <- topTable %>%
    unite("Range", ID.start, ID.end, sep = "-") %>%
    unite("Location", ID.seqnames, Range, ID.strand, sep = ":") %>%
    dplyr::select(Geneid = ID.gene_id, 
                  Symbol = ID.gene_name,
                  AveExpr, logFC, t, P.Value, 
                  FDR = adj.P.Val, 
                  Location, 
                  Entrez = ID.entrezid)
```

Now that we have our ranked list of genes, we should really inspect these visually.
A commonly used plot is a volcano plot, where the position of values on the x-axis is the logFC estimates for each gene, and the position on the y-axis relates to the strength of statistical significance for each gene.
Before plotting, we added a simple column called `DE` to indicate whether we considered a gene to be differentially expressed (ie. the mean between the groups is different), based purely on an FDR-adjusted p-value < 0.05.
To add some colour to the plot (and to make identifying the DE genes easy) we can use this `DE` status to colour points.

```{r volcanoPlot, fig.cap="Volcano plot showing DE genes between the two tissue types."}
topTable %>%
    mutate(DE = FDR < 0.05) %>%
    ggplot(aes(logFC, -log10(P.Value), colour = DE)) +
    geom_point(alpha = 0.5) +
    geom_text_repel(data = . %>%
                        dplyr::filter(DE) %>%
                        dplyr::filter(-log10(P.Value) > 4 | abs(logFC) > 5),
                    aes(label = Symbol)) +
    scale_colour_manual(values = c("grey", "red")) +
    theme_bw() +
    theme(legend.position = "none")
```

So what have we done here. Firstly we took our `topTable` object that contains the logFC values and FDR for each gene and piped the object into `mutate`. Here we have used `mutate` to create a new column called `DE` based on the logical question _is the value in the FDR column less than 0.05?_. For each row in our table if the value of the FDR column is < 0.05 a **TRUE** value will be returned, and of course a value of **FALSE** if $\geq$ 0.05.
As another perspective, we might like to see whether these genes are at the high or low end of the range for expression values.
This is often referred to as an MD plot, which stands for **M** ean expression vs **D** ifference, where difference is more commonly referred to as logFC.
We've added an `arrange()` call in the following to ensure our DE genes are plotted last and are the most visible in our figure.  

```{r plotMD, fig.cap="Mean-Difference plot showing fold-change potted against expression level. Genes considered as DE are highlighted in red.", results='asis'}
topTable %>%
    mutate(DE = FDR < 0.05) %>%
    arrange(desc(P.Value)) %>%
    ggplot(aes(AveExpr, logFC, colour = DE)) +
    geom_point(alpha = 0.5) +
    geom_text_repel(data = . %>%
                        dplyr::filter(DE) %>%
                        dplyr::filter(abs(logFC) > 5 | AveExpr > 14),
                    aes(label = Symbol)) +
    scale_colour_manual(values = c("grey", "red")) +
    labs(x = "Average Expression (log2 CPM)",
         y = "log Fold-Change") +
    theme_bw() +
    theme(legend.position = "none")
```

If were happy with our results, we could exprt this list using `write_csv()` or `write_tsv()`.
We could also produce a short table summarising the "big guns" in the dataset.
As there are more than 100 genes considered as DE here, let's restrict to those with logFC beyond the range $\pm2.3$, which equates to 5-fold up or down-regulation.

```{r printTopTab, results='asis'}
topTable %>%
    dplyr::filter(FDR < 0.05, abs(logFC) > 5) %>%
    dplyr::select(ID = Geneid, Symbol, AveExpr, logFC, P.Value, FDR) %>%
    pander(caption = paste("The", nrow(.), "most differentially expressed genes when ranked by p-value, and filtered on a logFC beyond the range $\\pm2.3$"))
```

We can also take a look at our genes of interest one at a time. Because we have two groups (ie. our two tissue types) a simple box plot provides a good summary of our count data.

Here we take a _gene of interest_ "ENSMUSG00000033021", and produce a box plot of expression values split by tissue type. I have considered "ENSMUSG00000033021" to be interesting because it is both significantly differentially expressed, and highy expressed in the table we created above.

```{r boxPlots, fig.cap="Box plot showing mean differences in our gene of interest between tissue types.", results='asis'}
plotly::ggplotly(
dgeList_Filtered$counts %>%
  as.data.frame() %>%
  tibble::rownames_to_column() %>%
  dplyr::filter(., rowname %in% "ENSMUSG00000033021") %>%
  tibble::column_to_rownames() %>%
  t() %>%
  as.data.frame() %>%
  tibble::rownames_to_column("samplename") %>%
  left_join(., sampleGroups, by = "samplename") %>%
  ggplot() +
  geom_boxplot(aes(x = group, y = ENSMUSG00000033021,
                   fill = group)) +
  theme_bw()
)
```

#### Tasks

1. Use the table we created above to choose another gene of interest (or two or three) and create your own box plots based on the code chunk above.
2. Do the box plots you create make sense in the context of the comparison we set for the differential expression analysis?


